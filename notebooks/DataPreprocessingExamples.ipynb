{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended Data Pre-processing Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 2 Columns from a CSV and save as a npy file\n",
    "\n",
    "These get saved in a special folder, with a function later to combine them all into separate spam/ham CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rename_columns(filename, ID, text_column_name, class_column_name, tags_to_replace):\n",
    "    csv_data = pd.read_csv(filename)\n",
    "\n",
    "    export_data = csv_data[[text_column_name, class_column_name]].copy()\n",
    "\n",
    "    if class_column_name in export_data:\n",
    "        export_data[class_column_name].replace(tags_to_replace, inplace=True)\n",
    "\n",
    "    np.save('../Datasets/NumpyData/' + ID + '.npy', export_data.to_numpy())\n",
    "    print(export_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get an Email Body from an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "def extract_body_from_email(raw_email, file_path):\n",
    "    msg = BytesParser(policy=policy.default).parsebytes(raw_email)\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.iter_parts():\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                charset = part.get_content_charset()\n",
    "                return decode_payload(part.get_payload(decode=True), charset, file_path)\n",
    "    else:\n",
    "        charset = msg.get_content_charset()\n",
    "        return decode_payload(msg.get_payload(decode=True), charset, file_path)\n",
    "\n",
    "#This is really only necessary if you have emails that cover multiple languages. Most emails are UTF-8.\n",
    "def decode_payload(payload, charset, file_path):\n",
    "    encodings = [charset, 'utf-8', 'ascii', 'latin-1']\n",
    "    for enc in encodings:\n",
    "        if enc:\n",
    "            try:\n",
    "                return payload.decode(enc)\n",
    "            except (UnicodeDecodeError, LookupError):\n",
    "                continue\n",
    "    print(f\"Failed to decode email in file: {file_path}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the .npy files into a Spam and Ham CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_npy_files_and_combine_to_csv(directory, spam_output_csv, ham_output_csv):\n",
    "    npy_files = [f for f in os.listdir(directory) if f.endswith('.npy')]\n",
    "    print(f\"Found .npy files: {npy_files}\")\n",
    "    \n",
    "    spam_frames = []\n",
    "    ham_frames = []\n",
    "\n",
    "    for npy_file in npy_files:\n",
    "        npy_path = os.path.join(directory, npy_file)\n",
    "        data = np.load(npy_path, allow_pickle=True)\n",
    "        df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
    "        \n",
    "        spam_df = df[df['label'] == 'spam']\n",
    "        ham_df = df[df['label'] == 'ham']\n",
    "        \n",
    "        spam_frames.append(spam_df)\n",
    "        ham_frames.append(ham_df)\n",
    "    \n",
    "    combined_spam_df = pd.concat(spam_frames, ignore_index=True).drop_duplicates()\n",
    "    combined_ham_df = pd.concat(ham_frames, ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    combined_spam_df.to_csv(spam_output_csv, index=False)\n",
    "    combined_ham_df.to_csv(ham_output_csv, index=False)\n",
    "    \n",
    "    print(f\"Spam CSV saved to: {spam_output_csv}\")\n",
    "    print(f\"Ham CSV saved to: {ham_output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords and HTML from Email bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    try:\n",
    "        # Skip emails with no body text\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "\n",
    "        # Remove HTML\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        words = text.split()\n",
    "        no_stopwords = [word for word in words if word.lower() not in stopwords]\n",
    "        cleaned_text = \" \".join(no_stopwords)\n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the \"spam\" and \"ham\" labels to a consistent mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels_and_save(input_file, output_file, label_mapping):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['label'] = df['label'].map(label_mapping)\n",
    "    df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
